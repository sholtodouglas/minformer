{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import data_hf\n",
    "from modelling import model\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "model = reload(model)\n",
    "import data\n",
    "import data_hf\n",
    "data = reload(data)\n",
    "data_hf = reload(data_hf)\n",
    "import data_shae\n",
    "data_shae = reload(data_shae)\n",
    "import finetune\n",
    "finetune = reload(finetune)\n",
    "import download_data\n",
    "download_data = reload(download_data)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:This GCS path gs://minformer_data/pretrained_ckpt/v1/57000 does not contain the commit_success.txt file used to indicate a successfully written GCS checkpoint. If the checkpoint was originally saved with GCS, the checkpoint was not successfully written. If the checkpoint was saved differently and copied, you need to add commit_success.txt to the checkpoint directory.\n"
     ]
    }
   ],
   "source": [
    "cfg = model.Config(\n",
    "    d_model=2048,\n",
    "    ffw_multiplier=4,\n",
    "    query_heads=8,\n",
    "    key_heads=8,\n",
    "    num_layers=12,\n",
    "    key_dim=128,\n",
    "    vocab_size=8,\n",
    "    max_seq_len=8192,\n",
    "    causal=True,\n",
    "    use_attn_kernel=True,\n",
    "    weight_dtype_at_rest=jnp.float32,\n",
    "    active_weight_dtype=jnp.bfloat16,\n",
    "    rules=model.fsdp_rules,\n",
    "    mesh=model.create_mesh(),\n",
    "    max_lr=3e-5,\n",
    "    min_lr=3e-6,\n",
    "    warmup_steps=50,\n",
    "    total_steps=10000,\n",
    "    return_sae_intermediates=True,\n",
    ")\n",
    "\n",
    "# Checkpoint manager setup\n",
    "checkpoint_dir = \"gs://minformer_data/pretrained_ckpt/v1\"\n",
    "ckpt_manager = model.make_mngr(path=checkpoint_dir)\n",
    "\n",
    "weights, opt_state = model.load(ckpt_manager, cfg)\n",
    "start_step = ckpt_manager.latest_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "stage_2 = [ \"gs://minformer_data/shae_8k/tfrecords/record_*.tfrecord\"]\n",
    "iter = data_shae.create_iterator(\n",
    "    stage_1=[], stage_2=stage_2, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "process_batch = model.process_batch_shae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files for stage 1\n",
      "Found 2868 files for stage 2\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def fwd(weights, x, segment_ids):\n",
    "    _, internals, x = model.forward(x, segment_ids, weights, cfg)\n",
    "    last_nonzero = jnp.sum(segment_ids > 0, axis=-1)\n",
    "    indices = last_nonzero[:, None, None] - 1\n",
    "    last_xs = jnp.take_along_axis(x, indices, 1)\n",
    "    return last_xs, internals\n",
    "\n",
    "def input_shardings(\n",
    "    mesh, rules\n",
    ") -> tuple[jax.sharding.NamedSharding, jax.sharding.NamedSharding, jax.sharding.NamedSharding]:\n",
    "    logical_axes = {\n",
    "        \"x\": model.P(\"batch\", \"sequence\"),\n",
    "        \"segment_ids\": model.P(\"batch\", \"sequence\"),\n",
    "    }\n",
    "    physical_axes = jax.tree.map(partial(model._logical_to_sharding, mesh=mesh, rules=rules), logical_axes)\n",
    "    return physical_axes\n",
    "\n",
    "\n",
    "fwd = jax.jit(fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FSDPRules(batch='x', sequence=None, d_model='x', query_heads=None, key_heads=None, key_dim=None, ffw=None, vocab=None, conv_window=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "for batch in iter:\n",
    "    batch = jax.device_put({'x': batch['x'], 'segment_ids': batch['segment_ids']}, input_shardings(cfg.mesh, cfg.rules))\n",
    "    _, internals = fwd(weights, batch['x'], batch['segment_ids'])\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
